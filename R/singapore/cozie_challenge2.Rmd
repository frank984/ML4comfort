---
title: "cozie_challenge_2"
author: "Federico Cortese"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages loading

```{r}
# Load packages
library(scales)
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(lubridate)

library(sp)
library(spacetime)
# library(ozmaps)
library(sf)
#library(ggmap)
library(gstat)
library(automap)


load("cleaned_data.Rdata")
names(cozie_train)[1]="index"
names(cozie_test)[1]="index"

```

Target variables

```{r}
target_vars=c("q_earphones","q_noise_kind","q_noise_nearby","q_thermal_preference")
```

Let's keep only rows without NAs

```{r}
indx_rm=which(is.na(cozie_train[,target_vars[1]]))
cozie_train.clean=cozie_train[-indx_rm,]
summary(cozie_train.clean)
```

There is ambiguity between time and ws_timestamp_location. According to the kaggle challenge webpage:

- ws_timestamp_location is the timestamp of when the location data was retrieved. 
- Usually, the value in 'ws_timestamp_location' and 'index' are close together. 
- There are instances where the location information is much older than the watch survey response, i.e., ws_timestamp_location<<index. 
- In some instances, no location data was collected for the micro-survey. 
- In these cases, the longitude and latitude are zero.

The variance between 'ws_timestamp_location' and 'ws_timestamp_start' is negligible. Given that the latter doesn't contain any missing values, we'll retain it as the primary time index.

```{r}
tmp=c(cozie_train.clean[-indx_ws_t,]$ws_timestamp_location-cozie_train.clean[-indx_ws_t,]$ws_timestamp_start)
summary(as.numeric(abs(tmp)))
hist(as.numeric(abs(tmp)))
```

```{r}
cozie_train.clean=subset(cozie_train.clean,select=-c(index,ws_timestamp_location))
cozie_train.clean=cozie_train.clean %>% select(ws_timestamp_start,everything())
names(cozie_train.clean)[1]="time"
```


# ts variables

The following variables exhibit a high frequency of missing values. Additionally, the limited recorded values don't align with the time of observations for the target variables. As a result, we opt to $\textbf{temporarily}$ exclude these variables from our analysis.

```{r}
ts_vars=c("ts_oxygen_saturation","ts_heart_rate","ts_resting_heart_rate",
          "ts_stand_time","ts_step_count","ts_audio_exposure_environment",
          "ts_walking_distance")
summary(cozie_train[,ts_vars])
```

```{r}
cozie_train.clean=subset(cozie_train.clean,select=-c(ts_oxygen_saturation,
                                                     ts_heart_rate,ts_resting_heart_rate,
                                                     ts_stand_time, ts_step_count,
                                                     ts_walking_distance,ts_audio_exposure_environment)
                         )
summary(cozie_train.clean)
```

# Other not relevant variables

We're excluding it from our current analysis the following variables:

- dT, the duration between the current and the previous micro-survey response in minutes. 
- Standard deviations of the urban indexes, such as the Sky View Factor, the Green View Factor etc...
- Standard deviations of building morphology measures, such as Foorprint, Perimeter etc...
- id_unique, a unique identifier for the rows.
- ws_survey_count: increasing counter for each micro-survey response.


```{r}
cozie_train.clean=subset(cozie_train.clean,
                         select = -c(dT,
                                     Green.View.Stdev,Sky.View.Stdev,
                                     Building.View.Stdev,Road.View.Stdev,
                                     Visual.Complexity.Stdev,
                                     id_unique,
                                     Footprint.Stdev,Perimeter.Total,Perimeter.Stdev,
                                     Complexity.Stdev,
                                     ws_survey_count
                                     ))

summary(cozie_train.clean)
```

# Adjusting time observations to preferred frequency

ATTENZIONE: arrotondando al minuto abbiamo pi√π osservazioni con il medesimo record temporale.

```{r}
cozie_train.clean2=cozie_train.clean
cozie_train.clean2$time=round(cozie_train.clean2$time,"mins")
```

